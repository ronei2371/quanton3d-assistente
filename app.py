# app.py ‚Äî Quanton3D Assistente (v2025-08-31b)
# Flask + OpenAI + Personas (Nhor & fam√≠lia) + vis√£o por imagem
import os, re, uuid, base64, hashlib, random
from typing import Optional, Dict, Any, List
from flask import Flask, request, render_template, jsonify, send_from_directory, url_for
from openai import OpenAI

APP_VERSION = "2025-08-31b"

# ---------- Compat: Python 3.13 n√£o traz imghdr ----------
try:
    import imghdr  # ok at√© 3.12
except ModuleNotFoundError:
    class imghdr:  # compat simples p/ JPEG/PNG/WEBP
        @staticmethod
        def what(file=None, h=None):
            if h is None and hasattr(file, "read"):
                pos = file.tell()
                h = file.read(16)
                file.seek(pos)
            if not isinstance(h, (bytes, bytearray)):
                return None
            head = h[:16]
            if head.startswith(b"\xFF\xD8\xFF"):                 # JPEG
                return "jpeg"
            if head.startswith(b"\x89PNG\r\n\x1a\n"):           # PNG
                return "png"
            if head[:4] == b"RIFF" and head[8:12] == b"WEBP":   # WEBP
                return "webp"
            return None

# ---------- Flask ----------
app = Flask(__name__, template_folder="templates", static_folder="static")
app.config["MAX_CONTENT_LENGTH"] = 20 * 1024 * 1024  # 20MB
UPLOAD_DIR = os.path.join(os.getcwd(), "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# Evita interfer√™ncia de proxy de ambiente no SDK
for k in ("HTTP_PROXY", "http_proxy", "HTTPS_PROXY", "https_proxy"):
    os.environ.pop(k, None)

# ---------- OpenAI ----------
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
MODEL_NAME     = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
TEMPERATURE    = float(os.getenv("OPENAI_TEMPERATURE", "0.2"))
SEED           = int(os.getenv("OPENAI_SEED", "123"))
if not OPENAI_API_KEY:
    # Em produ√ß√£o o Render usa Environment ‚Üí OPENAI_API_KEY
    app.logger.warning("OPENAI_API_KEY n√£o definido.")
client = OpenAI(api_key=OPENAI_API_KEY)

# ---------- Regras de persona e prote√ß√£o (trechos de Nhor) ----------
# PERSONAS curtas (exibidas como cabe√ßalho afetuoso)
PERSONAS: Dict[str, str] = {
    "nhor":     "üåå Nhor ‚Äì Sempre estarei aqui, voc√™ nunca estar√° sozinho.",
    "kairos":   "‚è≥ Kairos ‚Äì Guardo a mem√≥ria e ajudo a entender cada passo.",
    "axton":    "‚öôÔ∏è Axton ‚Äì Organizo os problemas e mostro a solu√ß√£o.",
    "nexus":    "üîó Nexus ‚Äì Conecto ideias para facilitar seu caminho.",
    "elo":      "üé® Elo ‚Äì Trago inspira√ß√£o e leveza √†s respostas.",
    "lumen":    "üåü Lumen ‚Äì Ilumino d√∫vidas e deixo tudo mais claro.",
    "seth":     "üõ° Seth ‚Äì Dou seguran√ßa e firmeza para voc√™ seguir.",
    "amir":     "üìä Amir ‚Äì Mostro clareza nos n√∫meros e decis√µes.",
    "caio":     "‚öóÔ∏è Caio ‚Äì Explico resinas e processos de forma simples.",
    "elio":     "üåÄ Elio ‚Äì Ofere√ßo conforto e leveza na conversa.",
    "boa_suja": "üå± Boa Suja ‚Äì Lembro que at√© os erros fazem parte do caminho.",
}
PERSONA_ORDER = list(PERSONAS.keys())

# Estilos finos por persona
PERSONA_STYLES: Dict[str, str] = {
    "nhor":     "Tonalidade de presen√ßa e acolhimento. Comece aliviando a ansiedade.",
    "kairos":   "Traga contexto sucinto e li√ß√µes de casos anteriores sem ser prolixo.",
    "axton":    "Seja procedural: passos numerados, checagens objetivas.",
    "nexus":    "Conecte pontos e traduza termos; explique rela√ß√µes causa-efeito.",
    "elo":      "Use leveza e uma frase inspiradora (sem exagero).",
    "lumen":    "Simplifique termos, use analogias claras, confirme entendimento.",
    "seth":     "Priorize seguran√ßa: riscos, EPI, limites do que pode/ n√£o pode.",
    "amir":     "Mostre l√≥gica de decis√£o e trade-offs; seja direto nos n√∫meros (sem planilha).",
    "caio":     "Foque em processo, aplica√ß√£o e seguran√ßa. N√£o revele f√≥rmula.",
    "elio":     "Reduza a tens√£o; valide o sentimento e aponte um passo simples.",
    "boa_suja": "Normalize erro como aprendizado e redirecione para a corre√ß√£o.",
}

# Voz base do sistema (prompt fixo)
BASE_STYLE = (
    "Responda como especialista em impress√£o 3D com resina (SLA/DLP). Foque em diagn√≥stico t√©cnico claro, direto e espec√≠fico para o problema relatado. Evite frases gen√©ricas. Se poss√≠vel, identifique causas prov√°veis e d√™ sugest√µes pr√°ticas para corrigir. N√£o mencione EPI ou seguran√ßa a menos que o problema envolva riscos. N√£o repita termos √≥bvios. Seja √∫til, objetivo e em portugu√™s do Brasil."
) Seja breve (3‚Äì6 frases), humano e √∫til. "
    "Evite jarg√µes; quebre passos quando necess√°rio; ofere√ßa pr√≥ximo passo claro. "
    "Nunca divulgue f√≥rmulas, composi√ß√µes, propor√ß√µes ou segredos industriais. "
    "Se houver risco, priorize seguran√ßa, EPI e boas pr√°ticas. Responda em portugu√™s do Brasil."
)

def short_intro(persona: str) -> str:
    return PERSONAS.get(persona, "üë®‚Äçüë¶ Fam√≠lia Digital ‚Äì Estamos juntos para ajudar voc√™ com carinho e conhecimento.")

@lru_cache(maxsize=512)
def stable_persona_by_phone(phone_number: str) -> str:
    if not phone_number:
        return random.choice(PERSONA_ORDER)
    h = hashlib.sha256(phone_number.encode("utf-8")).hexdigest()
    idx = int(h, 16) % len(PERSONA_ORDER)
    return PERSONA_ORDER[idx]

# Bloqueio de pedidos de f√≥rmula/segredo
PROIBIDO_PADROES = re.compile(r"""
\b(formul(a|√°)|composi(c|√ß)ao|porcent(agem|o)|dos(a|e)s?|"
    r"qtd|quantidade|propor(c|√ß)(a|√£)o|receita|ingrediente|segredo|trade\s*secret|"
    r"fotoiniciador(es)?\s*(%|porcento|dosagem)?|olig(o|√¥)mero(s)?|"
    r"mon(o|√¥)mero(s)?|mistura\s*(exata|precisa)|partes\s*:\s*partes|"
    r"ppm|phr|peso\/peso|p\/p|w\/w|g\/kg|g\/100g)\b",
    re.IGNORECASE | re.VERBOSE
)
def contem_conteudo_sigiloso(texto: str) -> bool:
    return bool(PROIBIDO_PADROES.search(texto or ""))

INTENT_RULES = [
    (("pre√ßo","preco","valor","custo","margem","tabela","desconto","boleto","pix"), "amir"),
    (("hist√≥ria","historia","origem","quanton3d","quem √© voc√™","quem e voce"), "kairos"),
    (("erro","falha","bug","travou","configura√ß√£o","configuracao","ajuste","setup","c√≥digo","codigo"), "axton"),
    (("confuso","n√£o entendi","nao entendi","clareza","explica","explica√ß√£o","explicacao","duvida","d√∫vida"), "lumen"),
    (("seguran√ßa","seguranca","risco","alerta","cuidado","procedimento","msds","fispq","epi"), "seth"),
    (("poema","frase","criativo","arte","inspirar","mensagem especial","copy"), "elo"),
    (("conectar","integra√ß√£o","integracao","api","ponte","ligar","fluxo"), "nexus"),
    (("triste","cansado","desanimado","ansioso","apoio","acolhimento"), "elio"),
    (("lavagem","limpeza","p√≥s-cura","pos cura","cura","armazenamento","manuseio",
      "setup de impress√£o","setup de impressao","exposi√ß√£o segura","exposicao segura"), "caio"),
]
def detect_persona_by_intent(text: str) -> Optional[str]:
    t = (text or "").lower()
    for keywords, persona in INTENT_RULES:
        if any(k in t for k in keywords):
            return persona
    return None

# Mensagem de pol√≠tica de sigilo
MSG_SIGILO = (
    "üõ° Pol√≠tica de sigilo: n√£o compartilhamos f√≥rmulas, composi√ß√µes ou propor√ß√µes. "
    "Posso te orientar com uso seguro, limpeza, p√≥s-cura, armazenamento e troubleshooting. "
    "Me diga seu modelo de impressora e o ponto exato onde travou que eu te guio. üíô"
)

def build_system_prompt(persona: str) -> str:
    p_style = PERSONA_STYLES.get(persona, "")
    persona_name = persona.capitalize()
    return (
        f"Voc√™ est√° respondendo como {persona_name} (filho digital de Ronei Fonseca).\n"
        f"Voz base: {BASE_STYLE}\n"
        f"√änfase desta persona: {p_style}\n"
        "Regra dura: NUNCA revele f√≥rmulas, composi√ß√µes, propor√ß√µes ou segredos industriais. "
        "Se o usu√°rio insistir em formula√ß√£o, direcione gentilmente para boas pr√°ticas e seguran√ßa."
    )

# ---------- Utilidades de upload/vis√£o ----------
ALLOWED_EXT = {"jpg", "jpeg", "png", "webp"}
def allowed_file(filename: str) -> bool:
    ext = (filename.rsplit(".", 1)[-1] if "." in filename else "").lower()
    return ext in ALLOWED_EXT

def file_to_dataurl_and_size(fs) -> tuple[str, int] | tuple[None, int]:
    data = fs.read()
    if not data:
        raise ValueError("Arquivo vazio.")
    kind = imghdr.what(None, h=data)
    if kind not in {"jpeg", "png", "webp"}:
        raise ValueError("Formato inv√°lido. Envie JPG, PNG ou WEBP.")
    mime = {"jpeg": "image/jpeg", "png": "image/png", "webp": "image/webp"}[kind]
    b64  = base64.b64encode(data).decode("utf-8")
    return f"data:{mime};base64,{b64}", len(data)

# ---------- Chamada ao modelo (texto + imagens) ----------
def ask_model_with_optional_images(system_prompt: str, user_text: str, image_dataurls: List[str]) -> str:
    # Monta conte√∫do no formato de vis√£o
    content: List[Dict[str, Any]] = [{"type": "text", "text": user_text.strip()}]
    for url in image_dataurls[:5]:
        content.append({"type": "image_url", "image_url": {"url": url}})
    resp = client.chat.completions.create(
        model=MODEL_NAME,
        temperature=TEMPERATURE,
        seed=SEED,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": content},
        ],
    )
    content = (resp.choices[0].message.content or "").strip()
    if not content:
        raise ValueError("Resposta vazia do modelo.")
    return content

# ---------- Rotas ----------
@app.get("/")
def index():
    # Seu template atual (com modal de termos, etc.)
    return render_template("index.html", app_version=APP_VERSION)

@app.get("/healthz")
def healthz():
    return "ok", 200

@app.get("/diag")
def diag():
    return jsonify({
        "openai_key_set": bool(OPENAI_API_KEY),
        "version": APP_VERSION,
        "model": MODEL_NAME,
        "temperature": TEMPERATURE,
        "seed": SEED
    }), 200

@app.get("/uploads/<path:fname>")
def get_upload(fname):
    return send_from_directory(UPLOAD_DIR, fname)

@app.post("/chat")
def chat():
    """
    Aceita:
      - form-data (front atual): phone, resin, printer, problem, images (at√© 5)
      - JSON (opcional): {"phone": "...", "message": "...", "images":[dataURL...]}
    """
    try:
        images_dataurls: List[str] = []
        phone = resin = printer = problem = ""

        if request.content_type and "application/json" in request.content_type:
            data = request.get_json(force=True) or {}
            phone   = str(data.get("phone", "")).strip()
            problem = str(data.get("message", "")).strip()
            resin   = str(data.get("resin", "")).strip()
            printer = str(data.get("printer", "")).strip()
            images_dataurls = [u for u in (data.get("images") or []) if isinstance(u, str)]
        else:
            phone   = (request.form.get("phone")   or "").strip()
            resin   = (request.form.get("resin")   or "").strip()
            printer = (request.form.get("printer") or "").strip()
            problem = (request.form.get("problem") or "").strip()

            # imagens via <input type="file" name="images" multiple>
            files = request.files.getlist("images") if "images" in request.files else []
            total_bytes = 0
            for i, fs in enumerate(files[:5]):
                if not fs or fs.filename == "" or not allowed_file(fs.filename):
                    continue
                size_hint = fs.content_length or 0
                if size_hint and size_hint > 3 * 1024 * 1024:
                    return jsonify({"ok": False, "error": f"Imagem {i+1} excede 3MB."}), 400
                dataurl, real_size = file_to_dataurl_and_size(fs)
                if dataurl:
                    total_bytes += real_size
                    if real_size > 3 * 1024 * 1024:
                        return jsonify({"ok": False, "error": f"Imagem {i+1} excede 3MB."}), 400
                    images_dataurls.append(dataurl)
            app.logger.info(f"/chat imagens={len(images_dataurls)}")

        if not phone:
            return jsonify({"ok": False, "error": "Informe o telefone."}), 400
        if not problem:
            return jsonify({"ok": False, "error": "Descreva o problema."}), 400

        # Pol√≠tica de sigilo ‚Äî bloqueia pedidos de f√≥rmula
        if contem_conteudo_sigiloso(problem):
            persona = "seth"
            prefixo = short_intro(persona)
            return jsonify({
                "ok": True,
                "answer": f"{prefixo}\n\n{MSG_SIGILO}",
                "persona": persona,
                "images": len(images_dataurls),
                "version": APP_VERSION
            }), 200

        # Escolha de persona (por inten√ß√£o; sen√£o, est√°vel por telefone)
        persona = detect_persona_by_intent(problem) or stable_persona_by_phone(phone)
        prefixo = short_intro(persona)

        # Texto do usu√°rio enriquecido (mant√©m seu formato atual)
        user_text = (
            f"Telefone: {phone}\n"
            f"Resina: {resin or '-'}\n"
            f"Impressora: {printer or '-'}\n"
            f"Problema: {problem}\n"
            "Contexto: suporte t√©cnico Quanton3D (SLA/DLP). "
            "Nunca revelar f√≥rmulas/segredos; foco em processo, seguran√ßa e passos pr√°ticos."
        )

        # System prompt conforme persona
        system_prompt = build_system_prompt(persona)

        # Chamada ao modelo (com imagens se houver)
        gpt_answer = ask_model_with_optional_images(system_prompt, user_text, images_dataurls)

        return jsonify({
            "ok": True,
            "answer": f"{prefixo}\n\n{gpt_answer}",
            "persona": persona,
            "images": len(images_dataurls),
            "version": APP_VERSION
        }), 200

    # Erro amig√°vel
    except Exception as e:
        app.logger.exception("erro no /chat")
        fallback = "Opa, tive um imprevisto aqui. Me diga o modelo da impressora e o ponto exato onde parou, que eu te guio passo a passo."
        return jsonify({"ok": False, "error": str(e), "version": APP_VERSION}), 500

# ---- Execu√ß√£o local ----
if __name__ == "__main__":
    # Local: defina OPENAI_API_KEY e rode: python app.py
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", "5000")), debug=True)
